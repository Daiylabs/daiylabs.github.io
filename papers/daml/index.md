# Discrete approach to machine learning

This is the landing page of the article. Here you can find alternative versions of the article as well as the supplementary materials, model data files, like videos and high resolution images that were too big to be included in the article itself.

## Links

- [English version of the article](https://arxiv.org/abs/2508.00869) (approx. 8 MB)

To be added (work in progress):
- Russian version of the article
- Source code
- Model files
- Image and video gallery

## Abstract

The article explores an encoding and structural information processing approach using sparse bit vectors and fixed-length linear vectors.

The following are presented:
- A discrete method of speculative stochastic dimensionality reduction of multidimensional code and linear spaces with linear asymptotic complexity;
- A geometric method for obtaining discrete embeddings of an organised code space that reflect the internal structure of a given modality.

The structure and properties of a code space are investigated using three modalities as examples: morphology of Russian and English languages, and immunohistochemical markers.

Parallels are drawn between the resulting map of the code space layout and so-called pinwheels appearing on the mammalian neocortex. A cautious assumption is made about similarities between neocortex organisation and processes happening in our models.

## Cite us

We are kindly asking you to use the following BibTex entry if you find our work useful:

```bib
@misc{kashitsyn2025discreteapproachmachinelearning,
      title={Discrete approach to machine learning}, 
      author={Dmitriy Kashitsyn and Dmitriy Shabanov},
      year={2025},
      eprint={2508.00869},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2508.00869}, 
}
```
